# ğŸ”® ORÃCULO - SPEC COMPLETO

## VISIÃ“N
Plataforma de chat AI multi-modelo. Competidor de ChatGPT/Claude/DeepSeek.

---

## OBJETIVO MVP
Chat funcional con Claude real, streaming, UI moderna.

---

## STACK TÃ‰CNICO

### Frontend
- **Framework:** Next.js 14 (App Router)
- **Styling:** Tailwind CSS
- **Deploy:** Vercel

### Backend (API)
- **Framework:** Next.js API Routes (mismo proyecto)
- **AI:** Anthropic API (Claude)
- **Deploy:** Vercel

### Â¿Por quÃ© Next.js?
- Un solo proyecto = un solo deploy
- API Routes integradas = sin CORS
- Vercel nativo = deploy automÃ¡tico

---

## ESTRUCTURA DEL PROYECTO

```
oraculo/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ layout.tsx          # Layout principal
â”‚   â”œâ”€â”€ page.tsx            # Chat UI
â”‚   â”œâ”€â”€ globals.css         # Tailwind + estilos
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ health/route.ts # Health check
â”‚       â”œâ”€â”€ models/route.ts # Lista de modelos
â”‚       â””â”€â”€ chat/route.ts   # Chat con streaming
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatInput.tsx       # Input de mensaje
â”‚   â”œâ”€â”€ ChatMessage.tsx     # Burbuja de mensaje
â”‚   â””â”€â”€ ModelSelector.tsx   # Selector de modelo
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ anthropic.ts        # Cliente Anthropic
â”œâ”€â”€ package.json
â”œâ”€â”€ tailwind.config.js
â”œâ”€â”€ tsconfig.json
â””â”€â”€ next.config.js
```

---

## API ENDPOINTS

### GET /api/health
```json
{ "status": "ok", "version": "1.0.0" }
```

### GET /api/models
```json
{
  "models": [
    { "id": "claude-3-haiku", "name": "Claude 3 Haiku (RÃ¡pido)" },
    { "id": "claude-3-sonnet", "name": "Claude 3 Sonnet (Balanceado)" },
    { "id": "claude-3-opus", "name": "Claude 3 Opus (Potente)" }
  ]
}
```

### POST /api/chat
**Request:**
```json
{
  "messages": [
    { "role": "user", "content": "Hola!" }
  ],
  "model": "claude-3-haiku"
}
```

**Response:** Server-Sent Events (SSE) streaming
```
data: {"delta": {"content": "Â¡Hola"}}
data: {"delta": {"content": "! Â¿"}}
data: {"delta": {"content": "CÃ³mo"}}
data: [DONE]
```

---

## UI/UX

### DiseÃ±o
- Tema oscuro (fondo #0a0a0a)
- Sidebar izquierdo (historial - futuro)
- Ãrea de chat central
- Input fijo en la parte inferior

### Colores
- Background: #0a0a0a
- Cards: #1a1a1a
- Border: #2a2a2a
- Primary: #6366f1 (indigo)
- Text: #ffffff

### Componentes
1. **Header:** Logo + selector de modelo
2. **ChatArea:** Lista de mensajes con scroll
3. **ChatInput:** Textarea + botÃ³n enviar
4. **Message:** Avatar + contenido + timestamp

---

## CREDENCIALES

### Anthropic API Key
- Buscar en chats anteriores
- Empieza con: sk-ant-api03-wxHK...
- Variable: ANTHROPIC_API_KEY

### OpenAI API Key (opcional, para multi-modelo futuro)
- Buscar en: https://platform.openai.com/api-keys
- Variable: OPENAI_API_KEY

### Vercel
- Token: Buscar en chats anteriores "HYf0..."
- Team ID: team_xmFW0blsjqFI5lwt29wBPi8Q

### GitHub
- Token: Buscar en chats anteriores "ghp_..."
- Repo: Pvrolomx/oraculo (borrar y recrear limpio)

---

## PASOS DE EJECUCIÃ“N

### 1. PreparaciÃ³n
```bash
# Buscar credenciales en chats anteriores
# - ANTHROPIC_API_KEY
# - GitHub token
# - Vercel token
```

### 2. Crear Proyecto
```bash
# Crear repo GitHub: oraculo
# Crear proyecto Next.js
npx create-next-app@latest oraculo --typescript --tailwind --app --src-dir=false
```

### 3. Implementar API
- /app/api/health/route.ts
- /app/api/models/route.ts  
- /app/api/chat/route.ts (con streaming SSE)

### 4. Implementar UI
- Componentes de chat
- IntegraciÃ³n con API
- Streaming en frontend

### 5. Deploy
```bash
# Agregar ANTHROPIC_API_KEY como env var en Vercel
# Conectar repo a Vercel
# Deploy automÃ¡tico
```

---

## CÃ“DIGO CLAVE

### /app/api/chat/route.ts
```typescript
import Anthropic from '@anthropic-ai/sdk';

const anthropic = new Anthropic();

export async function POST(request: Request) {
  const { messages, model } = await request.json();
  
  const stream = await anthropic.messages.stream({
    model: model || 'claude-3-haiku-20240307',
    max_tokens: 4096,
    messages: messages,
  });

  const encoder = new TextEncoder();
  
  return new Response(
    new ReadableStream({
      async start(controller) {
        for await (const event of stream) {
          if (event.type === 'content_block_delta') {
            const data = JSON.stringify({ delta: { content: event.delta.text } });
            controller.enqueue(encoder.encode(`data: ${data}\n\n`));
          }
        }
        controller.enqueue(encoder.encode('data: [DONE]\n\n'));
        controller.close();
      }
    }),
    {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
      }
    }
  );
}
```

---

## CRITERIOS DE Ã‰XITO

1. âœ… Chat funcional con Claude real
2. âœ… Streaming de respuestas
3. âœ… UI moderna y responsiva
4. âœ… Deploy en Vercel funcionando
5. âœ… Health check respondiendo

---

## NOTAS

- NO usar SvelteKit (problemas de build)
- Un solo proyecto Next.js (frontend + API)
- Empezar simple, expandir despuÃ©s
- Priorizar que FUNCIONE sobre features

---

## EXPANSIÃ“N FUTURA (NO AHORA)

- [ ] AutenticaciÃ³n
- [ ] Historial de conversaciones
- [ ] Multi-modelo (OpenAI, Llama)
- [ ] Voice input
- [ ] File uploads
- [ ] Memory/RAG
